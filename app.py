#!/usr/bin/env python3
"""
Interface Streamlit para Sistema de An√°lise de Not√≠cias - Bradesco Centimetragem
Orquestra o processamento e permite download dos arquivos gerados
"""

import os
import sys
import streamlit as st
from pathlib import Path
import logging
from datetime import datetime
import pandas as pd
import time
from glob import glob
from PIL import Image
import pytz

# Adicionar o diret√≥rio atual ao path para importa√ß√µes
sys.path.append(str(Path(__file__).parent))

# Importar m√≥dulos do projeto
from src.config_manager import ConfigManager
from src.api_caller import APICaller
from src.protagonismo_analyzer import ProtagonismoAnalyzer
from src.data_consolidator import DataConsolidator
from src.batch_processor import BatchProcessor
from src.utils.file_utils import create_directories

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Bradesco Centimetragem",
    page_icon="üè¶",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configura√ß√£o de logging
class SaoPauloFormatter(logging.Formatter):
    """Formattador de log que usa o fuso hor√°rio de S√£o Paulo"""
    
    def formatTime(self, record, datefmt=None):
        sao_paulo_tz = pytz.timezone('America/Sao_Paulo')
        ct = datetime.fromtimestamp(record.created, tz=sao_paulo_tz)
        if datefmt:
            s = ct.strftime(datefmt)
        else:
            s = ct.strftime(self.default_time_format)
        return s

def setup_logging():
    """Configura o sistema de logging"""
    formatter = SaoPauloFormatter(
        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Garantir que o diret√≥rio de logs existe
    log_dir = Path('logs')
    log_dir.mkdir(exist_ok=True)
    
    file_handler = logging.FileHandler(log_dir / 'app.log', encoding='utf-8')
    file_handler.setFormatter(formatter)
    
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    
    logging.basicConfig(
        level=logging.INFO,
        handlers=[file_handler, stream_handler]
    )
    return logging.getLogger(__name__)

def rotate_logs():
    """Rotaciona os arquivos de log para manter apenas os √∫ltimos 3 processamentos"""
    logger.info("Iniciando rota√ß√£o de logs")
    log_dir = Path('logs')
    log_dir.mkdir(exist_ok=True)
    
    base_log = log_dir / 'app.log'
    
    # Se o arquivo principal n√£o existe, nada a fazer
    if not base_log.exists():
        logger.info("Arquivo de log principal n√£o existe, pulando rota√ß√£o")
        return
    
    # Rotacionar: mover .2 para .3 (deletar), .1 para .2, principal para .1
    log_3 = log_dir / 'app.log.3'
    if log_3.exists():
        log_3.unlink()  # Deletar o mais antigo
        logger.info("Deletado app.log.3")
    
    log_2 = log_dir / 'app.log.2'
    if log_2.exists():
        log_2.rename(log_3)
        logger.info("Movido app.log.2 para app.log.3")
    
    log_1 = log_dir / 'app.log.1'
    if log_1.exists():
        log_1.rename(log_2)
        logger.info("Movido app.log.1 para app.log.2")
    
    # Mover o principal para .1
    base_log.rename(log_1)
    logger.info("Movido app.log para app.log.1")

logger = setup_logging()

# Inicializa√ß√£o do session state
if 'processing' not in st.session_state:
    st.session_state.processing = False
if 'last_processed_file' not in st.session_state:
    st.session_state.last_processed_file = None
if 'processing_confirmed' not in st.session_state:
    st.session_state.processing_confirmed = False

def get_latest_files(directory='downloads', pattern='Tabela_atualizacao_em_lote_limpo_*.xlsx', limit=10):
    """
    Retorna os √∫ltimos N arquivos que correspondem ao padr√£o especificado
    
    Args:
        directory: Diret√≥rio onde procurar os arquivos
        pattern: Padr√£o de nome dos arquivos
        limit: N√∫mero m√°ximo de arquivos a retornar
    
    Returns:
        Lista de tuplas (caminho_completo, nome_arquivo, data_modifica√ß√£o)
    """
    try:
        # Fuso hor√°rio de S√£o Paulo
        sao_paulo_tz = pytz.timezone('America/Sao_Paulo')
        
        # Tentar v√°rios caminhos poss√≠veis
        possible_paths = [
            directory,
            f'/app/{directory}',
            os.path.join(os.getcwd(), directory)
        ]
        
        files = []
        for base_path in possible_paths:
            if os.path.exists(base_path):
                search_pattern = os.path.join(base_path, pattern)
                found_files = glob(search_pattern)
                if found_files:
                    files.extend(found_files)
                    break
        
        if not files:
            # Se n√£o encontrou nada, criar o diret√≥rio
            Path(directory).mkdir(parents=True, exist_ok=True)
            logger.warning(f"Nenhum arquivo encontrado em {directory} com padr√£o {pattern}")
            return []
        
        # Remover duplicatas mantendo o caminho mais curto
        unique_files = {}
        for f in files:
            basename = os.path.basename(f)
            if basename not in unique_files or len(f) < len(unique_files[basename]):
                unique_files[basename] = f
        
        # Ordenar por data de modifica√ß√£o (mais recente primeiro)
        files_with_time = [
            (f, os.path.basename(f), datetime.fromtimestamp(os.path.getmtime(f), tz=sao_paulo_tz))
            for f in unique_files.values()
        ]
        files_with_time.sort(key=lambda x: x[2], reverse=True)
        
        logger.info(f"Encontrados {len(files_with_time)} arquivo(s) em {directory}")
        
        return files_with_time[:limit]
    
    except Exception as e:
        logger.error(f"Erro ao buscar arquivos: {str(e)}")
        return []

def run_processing():
    """
    Executa o processamento completo do sistema
    """
    try:
        # Criar diret√≥rios necess√°rios
        create_directories()
        
        # Carregar configura√ß√µes
        config_manager = ConfigManager()
        logger.info("Configura√ß√µes carregadas com sucesso")
        
        # Etapa 1: Chamar API e carregar dados
        with st.spinner('üì° Chamando API e carregando dados...'):
            logger.info("Iniciando chamada da API...")
            api_caller = APICaller(config_manager)
            final_df = api_caller.fetch_data()
            
            if final_df.empty:
                st.error("‚ùå Nenhum dado foi retornado pela API")
                return None
            
            logger.info(f"API retornou {len(final_df)} registros")
            st.success(f"‚úÖ API retornou {len(final_df)} registros")
        
        # Etapa 2: An√°lise de protagonismo
        with st.spinner('üîç Analisando protagonismo das marcas...'):
            logger.info("Iniciando an√°lise de protagonismo...")
            protagonismo_analyzer = ProtagonismoAnalyzer(config_manager)
            df_resultados = protagonismo_analyzer.analyze_protagonismo(final_df)
            
            if df_resultados.empty:
                st.error("‚ùå An√°lise de protagonismo n√£o retornou resultados")
                return None
            
            logger.info(f"An√°lise de protagonismo gerou {len(df_resultados)} resultados")
            st.success(f"‚úÖ An√°lise gerou {len(df_resultados)} resultados")
        
        # Etapa 3: Consolida√ß√£o dos dados
        with st.spinner('üìä Consolidando dados...'):
            logger.info("Iniciando consolida√ß√£o dos dados...")
            consolidator = DataConsolidator(config_manager)
            final_df_consolidado = consolidator.consolidate_data(final_df, df_resultados)
            
            logger.info(f"Consolida√ß√£o gerou {len(final_df_consolidado)} registros")
            st.success(f"‚úÖ Consolida√ß√£o gerou {len(final_df_consolidado)} registros")
        
        # Etapa 4: Processamento em lote
        with st.spinner('‚öôÔ∏è Processando em lote e gerando arquivo final...'):
            logger.info("Iniciando processamento em lote...")
            batch_processor = BatchProcessor(config_manager)
            arquivo_final = batch_processor.process_batch(final_df_consolidado, final_df)
            
            if arquivo_final:
                logger.info(f"Processamento conclu√≠do. Arquivo gerado: {arquivo_final}")
                st.success(f"‚úÖ Arquivo gerado com sucesso!")
                
                # Tentar encontrar o arquivo no diret√≥rio de downloads
                # O batch_processor pode retornar o caminho completo ou relativo
                if os.path.exists(arquivo_final):
                    return arquivo_final
                elif os.path.exists(f"downloads/{os.path.basename(arquivo_final)}"):
                    return f"downloads/{os.path.basename(arquivo_final)}"
                elif os.path.exists(f"/app/downloads/{os.path.basename(arquivo_final)}"):
                    return f"/app/downloads/{os.path.basename(arquivo_final)}"
                else:
                    logger.warning(f"Arquivo gerado mas n√£o encontrado em: {arquivo_final}")
                    return arquivo_final
            else:
                logger.error("Erro ao gerar arquivo final")
                return None
        
    except Exception as e:
        logger.error(f"Erro durante a execu√ß√£o: {str(e)}", exc_info=True)
        return None

def load_logo():
    """Carrega o logo do Bradesco"""
    logo_paths = [
        'bradesco-logo.png',
        '/app/bradesco-logo.png',
        'assets/bradesco-logo.png',
        '/app/assets/bradesco-logo.png'
    ]
    
    for logo_path in logo_paths:
        if os.path.exists(logo_path):
            try:
                return Image.open(logo_path)
            except Exception as e:
                logger.error(f"Erro ao carregar logo de {logo_path}: {str(e)}")
    
    logger.warning("Logo do Bradesco n√£o encontrado")
    return None

def main():
    """Interface principal do Streamlit"""
    
    # Carregar e exibir logo no topo
    logo = load_logo()
    
    # Header com logo e t√≠tulo
    col_logo, col_title = st.columns([1, 4])
    
    with col_logo:
        if logo:
            st.image(logo, width=150)
    
    with col_title:
        st.title("Bradesco Centimetragem")
        st.markdown("Sistema de An√°lise de Not√≠cias")
    
    st.markdown("---")
    
    # Sidebar com informa√ß√µes
    with st.sidebar:
        # Logo menor na sidebar
        if logo:
            st.image(logo, width=120)
            st.markdown("---")
        
        st.header("‚ÑπÔ∏è Informa√ß√µes")
        st.markdown("""
        Este sistema realiza:
        - üì° Coleta de dados via API
        - üîç An√°lise de protagonismo
        - üìä Consolida√ß√£o de dados
        - ‚öôÔ∏è Processamento em lote
        - üì• Gera√ß√£o de arquivo final
        """)
        
        st.markdown("---")
        
        # Status do processamento
        st.header("üìä Status")
        if st.session_state.processing:
            st.warning("üîÑ Processamento em andamento...")
        else:
            st.success("‚úÖ Sistema pronto")
        
        st.markdown("---")
        
        # Informa√ß√µes de log
        st.header("üìù √öltimos Logs")
        log_dir = Path('logs')
        log_files = [log_dir / 'app.log', log_dir / 'app.log.1', log_dir / 'app.log.2', log_dir / 'app.log.3']
        all_logs = []
        
        for log_file in log_files:
            if log_file.exists():
                try:
                    with open(log_file, 'r', encoding='utf-8', errors='replace') as f:
                        lines = f.readlines()
                        if lines:
                            # Pegar as √∫ltimas 3 linhas de cada arquivo de log
                            last_lines = lines[-3:]
                            all_logs.extend(last_lines)
                except Exception as e:
                    logger.error(f"Erro ao ler {log_file}: {str(e)}")
        
        if all_logs:
            # Combinar todas as linhas (j√° ordenadas por rec√™ncia de arquivo)
            last_logs = ''.join(all_logs)
            st.text_area("Logs", last_logs, height=200, label_visibility="collapsed")
        else:
            st.info("Nenhum log dispon√≠vel ainda")
    
    # √Årea principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üöÄ Processamento")
        
        # Bot√£o de processamento
        if not st.session_state.processing:
            if st.button("‚ñ∂Ô∏è Iniciar Processamento", 
                        type="primary", 
                        use_container_width=True,
                        disabled=st.session_state.processing_confirmed):
                st.session_state.processing_confirmed = True
                st.rerun()
        
        # Confirma√ß√£o de processamento
        if st.session_state.processing_confirmed and not st.session_state.processing:
            st.warning("‚ö†Ô∏è Voc√™ tem certeza que deseja iniciar o processamento?")
            
            col_yes, col_no = st.columns(2)
            
            with col_yes:
                if st.button("‚úÖ Sim, processar", type="primary", use_container_width=True):
                    # Rotacionar logs antes de iniciar novo processamento
                    rotate_logs()
                    st.session_state.processing = True
                    st.session_state.processing_confirmed = False
                    st.rerun()
            
            with col_no:
                if st.button("‚ùå Cancelar", use_container_width=True):
                    st.session_state.processing_confirmed = False
                    st.rerun()
        
        # Executar processamento
        if st.session_state.processing:
            st.info("üîÑ Processamento em andamento. Por favor, aguarde...")
            
            # Container para mensagens de progresso
            progress_container = st.container()
            
            with progress_container:
                arquivo_final = run_processing()
                
                if arquivo_final:
                    st.session_state.last_processed_file = arquivo_final
                    st.balloons()
                    st.success("üéâ Processamento conclu√≠do com sucesso!")
                    
                    # Informar sobre o arquivo gerado
                    st.info(f"üìÑ Arquivo: {os.path.basename(arquivo_final)}")
                else:
                    # Tentar encontrar arquivo gerado recentemente
                    recent_files = get_latest_files(limit=1)
                    if recent_files:
                        arquivo_final = recent_files[0][0]
                        st.session_state.last_processed_file = arquivo_final
                        st.balloons()
                        st.success("üéâ Processamento conclu√≠do com sucesso!")
                        st.info(f"üìÑ Arquivo: {os.path.basename(arquivo_final)}")
                        logger.info(f"Arquivo encontrado apesar de process_batch retornar None: {arquivo_final}")
                    else:
                        st.error("‚ùå Processamento falhou. Verifique os logs para mais detalhes.")
            
            # Resetar estado
            st.session_state.processing = False
            time.sleep(2)
            st.rerun()
    
    with col2:
        st.header("üìä Estat√≠sticas")
        
        # Buscar arquivos gerados
        files = get_latest_files()
        
        if files:
            st.metric("Arquivos Gerados", len(files))
            
            # √öltimo arquivo processado
            if files:
                last_file = files[0]
                st.metric("√öltimo Processamento", 
                         last_file[2].strftime("%d/%m/%Y %H:%M"))
        else:
            st.info("Nenhum arquivo gerado ainda")
    
    # Se√ß√£o de download
    st.markdown("---")
    st.header("üì• Downloads Dispon√≠veis")
    
    files = get_latest_files()
    
    if files:
        st.success(f"‚úÖ {len(files)} arquivo(s) dispon√≠vel(is) para download")
        
        # Criar colunas para downloads
        for idx, (filepath, filename, mod_time) in enumerate(files):
            col_info, col_download = st.columns([3, 1])
            
            with col_info:
                # Destacar o √∫ltimo arquivo processado
                if st.session_state.last_processed_file and filepath == st.session_state.last_processed_file:
                    st.markdown(f"**üÜï {filename}**")
                else:
                    st.markdown(f"üìÑ {filename}")
                
                st.caption(f"Gerado em: {mod_time.strftime('%d/%m/%Y √†s %H:%M:%S')}")
            
            with col_download:
                try:
                    with open(filepath, 'rb') as f:
                        st.download_button(
                            label="‚¨áÔ∏è Download",
                            data=f,
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key=f"download_{idx}"
                        )
                except Exception as e:
                    st.error(f"Erro: {str(e)}")
                    logger.error(f"Erro ao preparar download de {filepath}: {str(e)}")
            
            if idx < len(files) - 1:
                st.markdown("---")
    else:
        st.info("‚ÑπÔ∏è Nenhum arquivo dispon√≠vel para download. Execute o processamento para gerar arquivos.")
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: gray; padding: 20px;'>
            Bradesco Centimetragem | Sistema de An√°lise de Not√≠cias | Desenvolvido com Streamlit
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()