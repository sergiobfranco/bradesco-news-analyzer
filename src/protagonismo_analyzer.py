"""
M√≥dulo respons√°vel pela an√°lise de protagonismo usando DeepSeek API
Adaptado do c√≥digo original removendo filtros espec√≠ficos do iFood
VERS√ÉO ATUALIZADA: Inclui contagem de ocorr√™ncias das marcas e verifica√ß√£o de porta-vozes
VERS√ÉO CORRIGIDA: Bug de classifica√ß√£o de marca em termos compostos corrigido
VERS√ÉO 4.4: Corre√ß√£o do problema de porta-vozes aplicados a marcas sem classifica√ß√£o
VERS√ÉO 4.5: Corre√ß√£o da l√≥gica de cita√ß√£o m√≠nima para verificar marca isolada
VERS√ÉO 4.6: Corre√ß√£o adicional - content_check com c√≥pia expl√≠cita para garantir anula√ß√£o
VERS√ÉO 4.7: Logs super detalhados para debug do problema persistente
VERS√ÉO 4.8: Corre√ß√£o cr√≠tica do prompt - regra geral agora respeita marcas compostas
VERS√ÉO 4.9: Corre√ß√£o final - specific_requirements constru√≠do dinamicamente ap√≥s anula√ß√£o
VERS√ÉO 4.10: Debug extremo - log do prompt COMPLETO enviado ao DeepSeek
VERS√ÉO 5.0: CORRE√á√ÉO DEFINITIVA - Eliminada √∫ltima regra conflitante do prompt
VERS√ÉO 5.1: Remo√ß√£o completa da l√≥gica de capa - simplifica√ß√£o do c√≥digo
VERS√ÉO 5.2: Limpeza dos logs de debug excessivos - vers√£o production-ready
VERS√ÉO 5.3: Log espec√≠fico para controle de chamadas DeepSeek (ID, Marca, Resultado)
VERS√ÉO 5.4: Melhoria no prompt para classificar compara√ß√µes equilibradas como Conte√∫do
VERS√ÉO 5.5: Otimiza√ß√£o - verifica√ß√£o pr√©via de presen√ßa da marca antes de enviar ao DeepSeek
VERS√ÉO 5.6: CORRE√á√ÉO CR√çTICA - Removida inconsist√™ncia na l√≥gica do Santander como marca composta
VERS√ÉO 5.7: CORRE√á√ÉO FUNDAMENTAL - Pr√©-processamento aplicado apenas a marcas espec√≠ficas (Bradesco, BBI, Asset, √Ågora)
VERS√ÉO 5.8: RESTAURA√á√ÉO - Pr√©-processamento para todas as marcas, mas com contagem diferenciada (restritiva vs normal)
VERS√ÉO 5.9: ALINHAMENTO FINAL - Verifica√ß√£o de t√≠tulo aplicada a TODAS as marcas (restritiva + simples)
VERS√ÉO 5.10: CORRE√á√ÉO CR√çTICA DE BUGS - Fix 'Bradesco BBI'‚Üí'BBI' e contagem_usada inconsistente + logs debug
"""

import pandas as pd
import requests
import time
import re
import logging
import unicodedata
from datetime import datetime
from typing import List, Dict, Optional
from pathlib import Path
from src.config_manager import ConfigManager

class ProtagonismoAnalyzer:
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager
        self.logger = logging.getLogger(__name__)
        self.headers = config_manager.get_api_headers()
        # Carrega porta-vozes: dicion√°rio {normalizado: original} e lista de normalizados
        # ATUALIZADO: Usado para Bradesco, √Ågora, Bradesco Asset e BBI
        self.porta_vozes_map, self.porta_vozes = self._load_porta_vozes()
    
    def _normalize_text(self, text: str) -> str:
        """
        Remove acentos e normaliza texto para compara√ß√£o
        
        Args:
            text: Texto a ser normalizado
            
        Returns:
            Texto sem acentos e em min√∫sculas
        """
        # Remove acentos usando NFD (Normalization Form Canonical Decomposition)
        nfd = unicodedata.normalize('NFD', text)
        text_sem_acento = ''.join(char for char in nfd if unicodedata.category(char) != 'Mn')
        return text_sem_acento.lower()
    
    def _clean_channel_field(self, canais_text: str) -> str:
        """
        Limpa o campo Canais removendo colchetes, √°spas e caracteres especiais
        que podem atrapalhar a detec√ß√£o de marcas
        
        Args:
            canais_text: Texto original do campo Canais
            
        Returns:
            Texto limpo sem colchetes, √°spas e espa√ßos extras
        
        Exemplo:
            Input: "['', '', '√Ågora'], Bradesco, Santander"
            Output: "√Ågora, Bradesco, Santander"
        """
        if not canais_text:
            return ""
        
        # Remove colchetes, √°spas simples e duplas
        texto_limpo = canais_text.replace('[', '').replace(']', '')
        texto_limpo = texto_limpo.replace("'", '').replace('"', '')
        
        # Remove espa√ßos duplicados e v√≠rgulas m√∫ltiplas
        texto_limpo = re.sub(r'\s+', ' ', texto_limpo)
        texto_limpo = re.sub(r',\s*,+', ',', texto_limpo)
        
        # Remove v√≠rgulas no in√≠cio/fim e espa√ßos
        texto_limpo = texto_limpo.strip().strip(',').strip()
        
        return texto_limpo
    
    def _load_porta_vozes(self) -> tuple[Dict[str, str], List[str]]:
        """
        Carrega lista de porta-vozes do arquivo mais recente
        ATUALIZADO: Usado para Bradesco, √Ågora, Bradesco Asset e BBI
        
        Returns:
            Tupla contendo:
            - Dicion√°rio {nome_normalizado: nome_original} para manter capitaliza√ß√£o
            - Lista de nomes normalizados para busca r√°pida
        """
        try:
            config_path = Path("config")
            
            # Busca todos os arquivos que come√ßam com porta_vozes_
            arquivos_porta_vozes = list(config_path.glob("porta_vozes_*.xlsx"))
            
            if not arquivos_porta_vozes:
                self.logger.warning("Nenhum arquivo de porta-vozes encontrado na pasta config")
                return {}, []
            
            # Ordena por nome (timestamp no nome) e pega o mais recente
            arquivo_mais_recente = sorted(arquivos_porta_vozes, reverse=True)[0]
            
            self.logger.info(f"Carregando porta-vozes do arquivo: {arquivo_mais_recente.name}")
            
            # L√™ arquivo sem header (apenas uma coluna)
            df_porta_vozes = pd.read_excel(arquivo_mais_recente, header=None)
            
            # Extrai nomes: cria dicion√°rio e lista
            porta_vozes_map = {}  # {normalizado: original}
            porta_vozes_list = []  # [normalizado1, normalizado2, ...]
            
            for nome in df_porta_vozes[0].dropna():
                nome_original = str(nome).strip()
                nome_normalizado = self._normalize_text(nome_original)
                
                if nome_normalizado:
                    porta_vozes_map[nome_normalizado] = nome_original
                    porta_vozes_list.append(nome_normalizado)
            
            self.logger.info(f"Carregados {len(porta_vozes_list)} porta-vozes (Bradesco e √Ågora)")
            self.logger.debug(f"Primeiros 5 porta-vozes: {list(porta_vozes_map.values())[:5]}...")
            
            return porta_vozes_map, porta_vozes_list
            
        except Exception as e:
            self.logger.error(f"Erro ao carregar arquivo de porta-vozes: {str(e)}")
            return {}, []
    
    def _check_porta_voz_mentioned(self, titulo: str, conteudo: str) -> List[str]:
        """
        Verifica se algum porta-voz (Bradesco ou √Ågora) √© mencionado no texto
        
        Args:
            titulo: T√≠tulo da not√≠cia
            conteudo: Conte√∫do da not√≠cia
            
        Returns:
            Lista de nomes de porta-vozes encontrados com capitaliza√ß√£o ORIGINAL (vazia se nenhum encontrado)
        """
        if not self.porta_vozes:
            return []
        
        # Combina t√≠tulo e conte√∫do e normaliza
        texto_completo = f"{titulo} {conteudo}"
        texto_normalizado = self._normalize_text(texto_completo)
        
        # Lista para armazenar porta-vozes encontrados (com capitaliza√ß√£o original)
        porta_vozes_encontrados = []
        
        # Busca cada porta-voz no texto
        for porta_voz_normalizado in self.porta_vozes:
            # Usa word boundary para evitar matches parciais
            pattern = r'\b' + re.escape(porta_voz_normalizado) + r'\b'
            if re.search(pattern, texto_normalizado):
                # Adiciona o nome ORIGINAL (com capitaliza√ß√£o) √† lista
                nome_original = self.porta_vozes_map.get(porta_voz_normalizado, porta_voz_normalizado)
                porta_vozes_encontrados.append(nome_original)
        
        return porta_vozes_encontrados
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CORRE√á√ÉO: NOVOS M√âTODOS PARA RESOLVER BUG DE MARCAS COMPOSTAS
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _get_marcas_compostas_para_marca_base(self, marca_base: str) -> List[str]:
        """
        Retorna lista de marcas compostas que cont√™m a marca base
        
        Exemplos:
            marca_base="Bradesco" ‚Üí ["Bradesco Asset", "Bradesco BBI"]
            marca_base="Ita√∫" ‚Üí ["Ita√∫ Unibanco"]
        
        Args:
            marca_base: Marca base (ex: "Bradesco")
        
        Returns:
            list: Lista de marcas compostas
        """
        todas_marcas = self.config.w_marcas
        marcas_compostas = []
        marca_base_lower = marca_base.lower()
        
        # Primeiro: busca nas marcas configuradas
        for marca in todas_marcas:
            marca_lower = marca.lower()
            # Se a marca cont√©m a base mas n√£o √© igual (√© composta)
            if marca_base_lower in marca_lower and marca_lower != marca_base_lower:
                marcas_compostas.append(marca)
        
        # Segundo: adiciona combina√ß√µes conhecidas que podem n√£o estar em w_marcas
        combinacoes_conhecidas = {
            'bradesco': ['Bradesco Asset', 'Bradesco BBI'],  # Bradesco exclui suas compostas
            'itau': ['Ita√∫ Unibanco'],  # Ita√∫ exclui suas compostas
            'agora': [],  # √Ågora n√£o tem compostas conhecidas
            # NOTA: BBI N√ÉO tem 'Bradesco BBI' como composta porque deve CONTAR, n√£o excluir
            # NOTA: Santander removido - deve seguir l√≥gica normal, n√£o de marca composta
        }
        
        marca_normalizada = marca_base_lower.replace('√º', 'u').replace('√°', 'a')
        if marca_normalizada in combinacoes_conhecidas:
            for marca_composta in combinacoes_conhecidas[marca_normalizada]:
                if marca_composta not in marcas_compostas:
                    marcas_compostas.append(marca_composta)
        
        return marcas_compostas
    
    def _verificar_marca_isolada_no_titulo(self, marca: str, titulo: str, 
                                           marcas_compostas: List[str]) -> bool:
        """
        Verifica se a marca aparece ISOLADA no t√≠tulo (n√£o como parte de termo composto)
        
        Exemplos:
            marca="Bradesco", titulo="Bradesco Asset adia..." ‚Üí False
            marca="Bradesco", titulo="Bradesco anuncia..." ‚Üí True
        
        Args:
            marca: Nome da marca (ex: "Bradesco")
            titulo: T√≠tulo da not√≠cia
            marcas_compostas: Lista de marcas compostas que cont√™m a marca base
        
        Returns:
            bool: True se a marca aparece isolada, False se faz parte de termo composto
        """
        titulo_lower = titulo.lower()
        marca_lower = marca.lower()
        
        # Primeiro verifica se a marca existe no t√≠tulo
        if marca_lower not in titulo_lower:
            return False
        
        # Verificar se alguma das marcas compostas est√° presente
        for marca_composta in marcas_compostas:
            if marca_composta.lower() in titulo_lower:
                self.logger.debug(
                    f"Marca '{marca}' encontrada no t√≠tulo, mas faz parte de '{marca_composta}' - "
                    f"n√£o ser√° classificada automaticamente como Dedicada"
                )
                return False
        
        # Se chegou aqui, a marca aparece isolada
        # Verificar usando word boundary para ter certeza
        pattern = r'\b' + re.escape(marca_lower) + r'\b'
        if re.search(pattern, titulo_lower):
            self.logger.debug(
                f"Marca '{marca}' encontrada ISOLADA no t√≠tulo - "
                f"Classifica√ß√£o autom√°tica: Dedicada"
            )
            return True
        
        return False
    
    def _count_marca_occurrences_simple(self, marca: str, titulo: str, conteudo: str) -> int:
        """
        Conta ocorr√™ncias da marca usando word boundary simples (para Santander/Ita√∫)
        
        Args:
            marca: Nome da marca
            titulo: T√≠tulo da not√≠cia  
            conteudo: Conte√∫do da not√≠cia
            
        Returns:
            int: N√∫mero de ocorr√™ncias
        """
        texto_completo = f"{titulo} {conteudo}".lower()
        marca_lower = marca.lower()
        pattern = r'\b' + re.escape(marca_lower) + r'\b'
        matches = re.findall(pattern, texto_completo, re.IGNORECASE)
        return len(matches)
    
    def _verificar_marca_isolada_no_titulo_simples(self, marca: str, titulo: str) -> bool:
        """
        Verifica se a marca aparece no t√≠tulo usando verifica√ß√£o simples (para Santander/Ita√∫)
        
        Args:
            marca: Nome da marca
            titulo: T√≠tulo da not√≠cia
            
        Returns:
            bool: True se marca aparece no t√≠tulo
        """
        titulo_lower = titulo.lower()
        marca_lower = marca.lower()
        
        # Verifica√ß√£o simples com word boundary
        pattern = r'\b' + re.escape(marca_lower) + r'\b'
        if re.search(pattern, titulo_lower):
            self.logger.debug(
                f"Marca '{marca}' encontrada no t√≠tulo - "
                f"Classifica√ß√£o autom√°tica: Dedicada"
            )
            return True
        
        return False
    
    def _count_marca_occurrences_fixed(self, marca: str, titulo: str, conteudo: str, 
                                       marcas_compostas: List[str]) -> int:
        """
        Conta quantas vezes a marca aparece ISOLADA no texto (n√£o como parte de termo composto)
        
        Estrat√©gia:
            1. Substitui todas marcas compostas por placeholders
            2. Conta apenas a marca isolada
            
        Exemplos:
            texto="Bradesco Asset e Bradesco anunciam..."
            marca="Bradesco", marcas_compostas=["Bradesco Asset"]
            ‚Üí Retorna 1 (apenas o "Bradesco" isolado)
        
        Args:
            marca: Nome da marca (ex: "Bradesco")
            titulo: T√≠tulo da not√≠cia
            conteudo: Conte√∫do da not√≠cia
            marcas_compostas: Lista de marcas compostas que cont√™m a marca base
        
        Returns:
            int: N√∫mero de ocorr√™ncias ISOLADAS da marca
        """
        # Combinar t√≠tulo e conte√∫do
        texto_completo = f"{titulo} {conteudo}"
        texto_lower = texto_completo.lower()
        marca_lower = marca.lower()
        
        # PRIMEIRO: Substituir temporariamente todas as ocorr√™ncias de marcas compostas
        # por um placeholder para n√£o cont√°-las
        # IMPORTANTE: Usar placeholder √∫nico que n√£o cont√©m as palavras originais
        texto_modificado = texto_lower
        marcas_ordenadas = sorted(marcas_compostas, key=len, reverse=True)
        
        for i, marca_composta in enumerate(marcas_ordenadas):
            marca_composta_lower = marca_composta.lower()
            # Usar placeholder √∫nico baseado no √≠ndice
            placeholder = f'___MARCA_COMPOSTA_{i}___'
            texto_modificado = texto_modificado.replace(marca_composta_lower, placeholder)
        
        # SEGUNDO: Contar apenas a marca isolada no texto modificado
        pattern = r'\b' + re.escape(marca_lower) + r'\b'
        matches = re.findall(pattern, texto_modificado)
        
        contagem = len(matches)
        
        # Log para debug
        if contagem > 0:
            self.logger.debug(
                f"Marca '{marca}' encontrada {contagem} vez(es) ISOLADA no texto "
                f"(excluindo ocorr√™ncias em: {marcas_compostas})"
            )
        
        return contagem
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # FIM DOS NOVOS M√âTODOS PARA CORRE√á√ÉO
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def analyze_protagonismo(self, final_df: pd.DataFrame) -> pd.DataFrame:
        """
        Analisa o n√≠vel de protagonismo para cada not√≠cia e marca
        ATUALIZADO: Inclui contagem de ocorr√™ncias no formato largo
        """
        try:
            # Carrega a tabela de protagonismo
            df_protagonismo = self._load_protagonismo_table()
            
            if df_protagonismo.empty:
                self.logger.error("Tabela de protagonismo n√£o p√¥de ser carregada")
                return pd.DataFrame()
            
            # Processa not√≠cias no formato largo com contagem de ocorr√™ncias
            df_resultados = self._process_noticias_formato_largo(final_df, df_protagonismo)
            
            if not df_resultados.empty:
                self.logger.info(f"An√°lise conclu√≠da: {len(df_resultados)} not√≠cias processadas")
                
                # Aplica corre√ß√£o p√≥s-processamento
                df_resultados = self._correct_missing_classifications_largo(df_resultados, final_df)
                
                # Aplica substitui√ß√µes dos n√≠veis
                df_resultados = self._apply_nivel_substitutions_largo(df_resultados)
                
                # Salva resultados
                self._save_results_largo(df_resultados)
            
            return df_resultados
            
        except Exception as e:
            self.logger.error(f"Erro durante an√°lise de protagonismo: {str(e)}")
            raise
    
    def _load_protagonismo_table(self) -> pd.DataFrame:
        """
        Carrega a tabela de n√≠veis de protagonismo
        """
        try:
            df_protagonismo = pd.read_excel(self.config.arq_protagonismo)
            self.logger.info(f"Tabela de protagonismo carregada: {self.config.arq_protagonismo}")
            
            if 'Nivel' not in df_protagonismo.columns or 'Conceito' not in df_protagonismo.columns:
                self.logger.error("Tabela de protagonismo n√£o cont√©m as colunas necess√°rias ('Nivel', 'Conceito')")
                return pd.DataFrame()
            
            return df_protagonismo
            
        except FileNotFoundError:
            self.logger.error(f"Arquivo de protagonismo n√£o encontrado: {self.config.arq_protagonismo}")
            return pd.DataFrame()
        except Exception as e:
            self.logger.error(f"Erro ao carregar tabela de protagonismo: {str(e)}")
            return pd.DataFrame()
    
    def _count_marca_occurrences(self, marca: str, titulo: str, conteudo: str) -> int:
        """
        Conta quantas vezes a marca aparece no texto (t√≠tulo + conte√∫do)
        
        REGRAS ESPECIAIS:
        - "Bradesco": conta apenas quando N√ÉO for seguido de "BBI" ou "Asset"
        - "BBI": conta "BBI" isolado + "Bradesco BBI" (sem contar o Bradesco)
        - "Bradesco Asset": conta apenas "Bradesco Asset" completo
        
        Args:
            marca: Nome da marca a ser contada
            titulo: T√≠tulo da not√≠cia
            conteudo: Conte√∫do da not√≠cia
        
        Returns:
            int: N√∫mero de ocorr√™ncias encontradas
        """
        # Combinar t√≠tulo e conte√∫do
        texto_completo = f"{titulo} {conteudo}".lower()
        marca_lower = marca.lower()
        
        # === REGRAS ESPECIAIS POR MARCA ===
        
        # 1. BRADESCO: Conta apenas quando N√ÉO for seguido de "BBI" ou "Asset"
        if marca_lower == "bradesco":
            # Pattern: "bradesco" que N√ÉO seja seguido de "bbi" ou "asset"
            # Negative lookahead: (?!\s+(bbi|asset)\b)
            pattern = r'\bbradesco\b(?!\s+(bbi|asset)\b)'
            matches = re.findall(pattern, texto_completo, re.IGNORECASE)
            return len(matches)
        
        # 2. BBI: Aceita "BBI" isolado OU "Bradesco BBI"
        elif marca_lower == "bbi":
            # Conta duas varia√ß√µes:
            # a) "Bradesco BBI" (completo)
            pattern_bradesco_bbi = r'\bbradesco\s+bbi\b'
            matches_bradesco_bbi = re.findall(pattern_bradesco_bbi, texto_completo, re.IGNORECASE)
            
            # b) "BBI" isolado (sem Bradesco antes)
            # Negative lookbehind: (?<!bradesco\s)
            pattern_bbi_isolado = r'(?<!bradesco\s)\bbbi\b'
            matches_bbi_isolado = re.findall(pattern_bbi_isolado, texto_completo, re.IGNORECASE)
            
            total = len(matches_bradesco_bbi) + len(matches_bbi_isolado)
            return total
        
        # 3. BRADESCO ASSET: Aceita apenas "Bradesco Asset" completo
        elif marca_lower == "bradesco asset":
            # Pattern: "bradesco asset" (completo)
            pattern = r'\bbradesco\s+asset\b'
            matches = re.findall(pattern, texto_completo, re.IGNORECASE)
            return len(matches)
        
        # 4. OUTRAS MARCAS: Contagem normal com word boundary
        else:
            pattern = r'\b' + re.escape(marca_lower) + r'\b'
            matches = re.findall(pattern, texto_completo, re.IGNORECASE)
            return len(matches)
    
    def _process_noticias_formato_largo(self, final_df: pd.DataFrame, df_protagonismo: pd.DataFrame) -> pd.DataFrame:
        """
        Processa cada not√≠cia para an√°lise de protagonismo e contagem de ocorr√™ncias
        ATUALIZADO: Retorna DataFrame no formato largo (uma linha por not√≠cia, colunas separadas por marca)
        CORRIGIDO: Bug de classifica√ß√£o de marca em termos compostos
        """
        required_columns = ['Id', 'Titulo', 'Conteudo', 'Canais']
        
        if not all(col in final_df.columns for col in required_columns):
            self.logger.error(f"Colunas necess√°rias n√£o encontradas: {required_columns}")
            return pd.DataFrame()
        
        # Criar DataFrame resultado com as colunas base
        resultado_df = final_df[['Id', 'UrlVisualizacao', 'UrlOriginal', 'Titulo']].copy()
        
        # Adicionar colunas para cada marca (protagonismo + contagem + porta-voz)
        for marca in self.config.w_marcas:
            resultado_df[f'Nivel de Protagonismo {marca}'] = None
            resultado_df[f'Ocorrencias {marca}'] = 0
            
            # ATUALIZADO: Porta-vozes para Bradesco, √Ågora, Bradesco Asset e BBI
            if marca in ['Bradesco', '√Ågora', 'Bradesco Asset', 'BBI']:
                resultado_df[f'Porta-Voz {marca}'] = None
        
        self.logger.info("Avaliando n√≠vel de protagonismo para cada not√≠cia e marca...")
        
        # Contador para estat√≠sticas
        total_noticias = len(final_df)
        noticias_processadas = 0
        noticias_filtradas = 0
        classificacoes_automaticas = 0
        upgrades_por_porta_voz = 0
        chamadas_deepseek = 0
        
        for index, row in final_df.iterrows():
            noticia_id = row['Id']
            titulo_noticia = str(row['Titulo']).strip()
            conteudo_noticia = str(row['Conteudo']).strip()
            canais_noticia = str(row['Canais']).strip()
            
            # NOVO: Limpa o campo Canais
            canais_noticia = self._clean_channel_field(canais_noticia)
            
            # Combina t√≠tulo e conte√∫do
            texto_completo_noticia = f"T√≠tulo: {titulo_noticia}\n\nConte√∫do: {conteudo_noticia}"
            
            if not texto_completo_noticia.strip():
                self.logger.warning(f"Pulando not√≠cia ID {noticia_id}: T√≠tulo e Conte√∫do vazios")
                continue
            
            # FILTRO: Verifica se pelo menos uma das marcas est√° presente no campo Canais
            marcas_no_canal = []
            for marca in self.config.w_marcas:
                if re.search(r'\b' + re.escape(marca.lower()) + r'\b', canais_noticia.lower()):
                    marcas_no_canal.append(marca)
            
            # Se nenhuma marca foi encontrada no campo Canais, pula a not√≠cia
            if not marcas_no_canal:
                noticias_filtradas += 1
                self.logger.debug(f"Not√≠cia ID {noticia_id} filtrada - nenhuma marca encontrada no campo Canais: {canais_noticia}")
                continue
            
            noticias_processadas += 1
            self.logger.debug(f"Processando not√≠cia ID {noticia_id} - Marcas encontradas no canal: {marcas_no_canal}")
            
            # ‚ïê‚ïê‚ïê NOVO: Detectar porta-vozes UMA VEZ por not√≠cia ‚ïê‚ïê‚ïê
            porta_vozes_noticia = self._check_porta_voz_mentioned(titulo_noticia, conteudo_noticia)
            marcas_com_porta_vozes = ['Bradesco', '√Ågora', 'Bradesco Asset', 'BBI']
            
            if porta_vozes_noticia:
                self.logger.debug(f"Porta-vozes detectados na not√≠cia ID {noticia_id}: {', '.join(porta_vozes_noticia)}")
            
            # Processa apenas as marcas encontradas no campo Canais
            for marca in marcas_no_canal:
                self.logger.debug(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - "
                                f"Avaliando not√≠cia ID {noticia_id} para a marca: {marca}")
                
                # Inicializar vari√°veis no in√≠cio de CADA itera√ß√£o
                nivel_detectado = None
                classificacao_automatica = False
                
                # ‚ïê‚ïê‚ïê OBTER MARCAS COMPOSTAS ‚ïê‚ïê‚ïê
                marcas_compostas = self._get_marcas_compostas_para_marca_base(marca)
                
                # ‚ïê‚ïê‚ïê CONTAGEM DE OCORR√äNCIAS ‚ïê‚ïê‚ïê
                contagem = self._count_marca_occurrences_fixed(marca, titulo_noticia, conteudo_noticia, marcas_compostas)
                
                # === PR√â-PROCESSAMENTO BASEADO EM CONTAGEM DE OCORR√äNCIAS ===
                # APLICAR PARA TODAS AS MARCAS, mas com diferentes tipos de contagem:
                # - Bradesco, BBI, Asset, √Ågora: contagem restritiva (marcas compostas)
                # - Santander, Ita√∫: contagem normal (padr√£o word boundary)
                
                marcas_com_preprocessamento_restritivo = ['Bradesco', 'BBI', 'Bradesco Asset', '√Ågora']
                
                # Para marcas com l√≥gica restritiva, usar contagem espec√≠fica
                if marca in marcas_com_preprocessamento_restritivo:
                    contagem_usada = contagem  # J√° calculada com _count_marca_occurrences_fixed
                    self.logger.debug(f"üîß DEBUG: Marca '{marca}' (restritiva) - contagem_fixed={contagem}, contagem_usada={contagem_usada}")
                else:
                    # Para Santander/Ita√∫, usar contagem normal (word boundary simples)
                    contagem_usada = self._count_marca_occurrences_simple(marca, titulo_noticia, conteudo_noticia)
                    self.logger.debug(f"üîß DEBUG: Marca '{marca}' (normal) - contagem_fixed={contagem}, contagem_simple={contagem_usada}")
                
                # Aplicar classifica√ß√£o autom√°tica para TODAS as marcas
                # CR√çTICO: N√£o pula quando contagem √© 0 - deixa ir para DeepSeek
                # O DeepSeek pode detectar a marca mesmo quando nossa contagem n√£o encontra
                
                # Regra 1: 5+ ocorr√™ncias = Dedicada
                if contagem_usada >= 5:
                    nivel_detectado = 'N√≠vel 1'  # Dedicada
                    classificacao_automatica = True
                    self.logger.debug(f"Marca '{marca}' com {contagem_usada} ocorr√™ncias - Classifica√ß√£o autom√°tica: Dedicada")
                    classificacoes_automaticas += 1
                
                # Regra 2: 3-4 ocorr√™ncias = Conte√∫do
                elif contagem_usada >= 3:
                    nivel_detectado = 'N√≠vel 2'  # Conte√∫do
                    classificacao_automatica = True
                    self.logger.debug(f"Marca '{marca}' com {contagem_usada} ocorr√™ncias - Classifica√ß√£o autom√°tica: Conte√∫do")
                    classificacoes_automaticas += 1
                
                # Regra 3: 1-2 ocorr√™ncias = Cita√ß√£o (verifica porta-voz para upgrade)
                elif contagem_usada >= 1:
                    nivel_detectado = 'N√≠vel 3'  # Cita√ß√£o
                    classificacao_automatica = True
                    self.logger.debug(f"Marca '{marca}' com {contagem_usada} ocorr√™ncias - Classifica√ß√£o autom√°tica: Cita√ß√£o")
                    classificacoes_automaticas += 1
                
                # NOVA L√ìGICA: Verifica√ß√£o de porta-vozes para TODAS as marcas com classifica√ß√£o autom√°tica
                if classificacao_automatica and marca in marcas_com_porta_vozes and porta_vozes_noticia:
                    # Aplica porta-vozes independentemente do n√≠vel de classifica√ß√£o
                    mask = resultado_df['Id'] == noticia_id
                    porta_vozes_str = ', '.join(porta_vozes_noticia)
                    resultado_df.loc[mask, f'Porta-Voz {marca}'] = porta_vozes_str
                    
                    # Se era Cita√ß√£o (1-2 ocorr√™ncias), faz upgrade para Conte√∫do
                    if contagem_usada >= 1 and contagem_usada <= 2:
                        nivel_detectado = 'N√≠vel 2'  # Upgrade para Conte√∫do
                        upgrades_por_porta_voz += 1
                        self.logger.debug(f"Marca '{marca}' com {contagem_usada} ocorr√™ncias + porta-vozes: {', '.join(porta_vozes_noticia)} - Upgrade para Conte√∫do")
                    else:
                        # Para 3+ ocorr√™ncias, mant√©m o n√≠vel mas aplica porta-vozes
                        self.logger.debug(f"Marca '{marca}' ({contagem_usada} ocorr√™ncias) + porta-vozes: {', '.join(porta_vozes_noticia)} - Mant√©m {nivel_detectado}")
                
                # ‚ïê‚ïê‚ïê VERIFICAR SE MARCA APARECE ISOLADA NO T√çTULO ‚ïê‚ïê‚ïê
                # APLICAR PARA TODAS AS MARCAS (conforme especifica√ß√£o correta)
                # Para marcas restritivas: usa l√≥gica de marcas compostas
                # Para marcas normais: usa verifica√ß√£o simples
                
                if marca in marcas_com_preprocessamento_restritivo:
                    # Marcas restritivas: verifica√ß√£o com l√≥gica de marcas compostas
                    marca_isolada_no_titulo = self._verificar_marca_isolada_no_titulo(
                        marca, titulo_noticia, marcas_compostas
                    )
                else:
                    # Marcas normais (Santander/Ita√∫): verifica√ß√£o simples no t√≠tulo
                    marca_isolada_no_titulo = self._verificar_marca_isolada_no_titulo_simples(
                        marca, titulo_noticia
                    )
                
                if marca_isolada_no_titulo:
                    # Marca isolada no t√≠tulo sempre √© Dedicada (sobrescreve classifica√ß√£o por contagem)
                    nivel_detectado = 'N√≠vel 1'  # Dedicada
                    classificacao_automatica = True
                    self.logger.debug(f"Marca '{marca}' encontrada ISOLADA no t√≠tulo - Dedicada (sobrescreve contagem)")
                    if contagem_usada < 5:  # S√≥ conta se n√£o foi contado antes
                        classificacoes_automaticas += 1
                
                # Se n√£o houve classifica√ß√£o autom√°tica, VERIFICAR SE MARCA EXISTE antes de enviar para DeepSeek
                if not classificacao_automatica:
                    # NOVA VERIFICA√á√ÉO: S√≥ enviar para DeepSeek se marca realmente aparece no texto
                    contagem_previa = self._count_marca_occurrences_fixed(
                        marca, titulo_noticia, conteudo_noticia, marcas_compostas
                    )
                    
                    if contagem_previa == 0:
                        # Marca n√£o aparece isolada no texto - n√£o enviar para DeepSeek
                        nivel_detectado = 'Nenhum N√≠vel Encontrado'
                        self.logger.debug(f"Marca '{marca}' n√£o encontrada no texto - Nenhum N√≠vel (sem chamar DeepSeek)")
                    else:
                        # Marca aparece no texto - prosseguir com DeepSeek
                        # Verifica regras espec√≠ficas de conte√∫do
                        content_check = self.config.check_specific_content_requirements(
                            canais_noticia, texto_completo_noticia
                        )
                    
                        # CORRE√á√ÉO: S√≥ aplicar cita√ß√£o m√≠nima se marca realmente aparece ISOLADA
                        if content_check['should_be_minimum_citation'] and marca == 'Bradesco':
                            # Verificar se Bradesco realmente aparece isolado no texto
                            contagem_isolada = self._count_marca_occurrences_fixed(
                                marca, titulo_noticia, conteudo_noticia, marcas_compostas
                            )
                            
                            if contagem_isolada > 0:
                                # S√≥ aplicar se Bradesco aparece isolado
                                specific_terms_info = content_check['found_specific_terms']
                                self.logger.debug(
                                    f"Cita√ß√£o m√≠nima aplicada para Bradesco (marca encontrada isolada): "
                                    f"{[t['content_term'] for t in specific_terms_info]}"
                                )
                            else:
                                # Criar novo content_check com cita√ß√£o m√≠nima anulada
                                self.logger.debug(
                                    f"Cita√ß√£o m√≠nima anulada para Bradesco: marca n√£o encontrada isolada "
                                    f"(s√≥ aparece em marcas compostas)"
                                )
                                # Criar c√≥pia do content_check com should_be_minimum_citation = False
                                content_check = content_check.copy()
                                content_check['should_be_minimum_citation'] = False
                        
                        # Faz an√°lise completa com DeepSeek
                        nivel_detectado = self._analyze_single_news_marca(
                            texto_completo_noticia, marca, df_protagonismo, noticia_id, 
                            canais_noticia, content_check, porta_vozes_noticia
                        )
                        
                        chamadas_deepseek += 1
                        # Pausa para evitar sobrecarregar a API
                        time.sleep(1)
                
                # Limitar ocorr√™ncias a no m√°ximo 10
                contagem = min(contagem, 10)
                
                # Salvar resultados no DataFrame formato largo
                mask = resultado_df['Id'] == noticia_id
                resultado_df.loc[mask, f'Nivel de Protagonismo {marca}'] = nivel_detectado
                resultado_df.loc[mask, f'Ocorrencias {marca}'] = contagem
                
                self.logger.debug(
                    f"Not√≠cia ID {noticia_id}, Marca {marca}: "
                    f"N√≠vel='{nivel_detectado}', Ocorr√™ncias={contagem}"
                )
        
        # Log de estat√≠sticas finais
        self.logger.info(f"Estat√≠sticas do processamento:")
        self.logger.info(f"- Total de not√≠cias na base: {total_noticias}")
        self.logger.info(f"- Not√≠cias processadas (com marcas no canal): {noticias_processadas}")
        self.logger.info(f"- Not√≠cias filtradas (sem marcas no canal): {noticias_filtradas}")
        self.logger.info(f"- Classifica√ß√µes autom√°ticas (por contagem/t√≠tulo): {classificacoes_automaticas}")
        self.logger.info(f"- Upgrades por porta-voz (Cita√ß√£o‚ÜíConte√∫do): {upgrades_por_porta_voz}")
        self.logger.info(f"- Chamadas enviadas ao DeepSeek: {chamadas_deepseek}")
        
        if noticias_processadas > 0:
            economia_percentual = (classificacoes_automaticas / noticias_processadas) * 100
            self.logger.info(f"- Economia de chamadas API: {economia_percentual:.1f}%")
        
        return resultado_df
    
    def _build_specific_requirements(self, content_check: dict, marca: str) -> str:
        """
        Constr√≥i os requisitos espec√≠ficos baseado no content_check ATUAL
        """
        if content_check and content_check.get('should_be_minimum_citation') and marca == 'Bradesco':
            found_terms = [t['content_term'] for t in content_check['found_specific_terms']]
            return f"""
        
        VERIFICA√á√ÉO ESPEC√çFICA PARA BRADESCO:
        Os seguintes termos espec√≠ficos foram encontrados no conte√∫do: {', '.join(found_terms)}
        Devido a essa verifica√ß√£o espec√≠fica, esta not√≠cia deve ser classificada no M√çNIMO como "N√≠vel 3" (Cita√ß√£o).
        """
        return ""
    
    def _analyze_single_news_marca(self, texto_noticia: str, marca: str, 
                                  df_protagonismo: pd.DataFrame, noticia_id: int,
                                  canais_noticia: str = "", content_check: dict = None,
                                  porta_vozes_global: List[str] = None) -> str:
        """
        Analisa uma √∫nica not√≠cia para uma marca espec√≠fica
        """
        # Prepara o prompt para o DeepSeek
        prompt_texto = f"""
        Analise o seguinte texto de not√≠cia e determine o n√≠vel de protagonismo da marca "{marca}".

        N√çVEIS DE PROTAGONISMO:

        **N√≠vel 1 - Dedicada:**
        - A marca √© o foco principal da mat√©ria
        - Destacada no t√≠tulo, subt√≠tulo ou lead
        - Exemplo: "Bradesco revoluciona o mercado financeiro com nova tecnologia"

        **N√≠vel 2 - Conte√∫do:**
        - Men√ß√£o significativa da marca, mas sem ser o foco ou refer√™ncia prim√°ria
        - A marca tem papel relevante mas n√£o √© o protagonista principal da not√≠cia
        
        a) **Compara√ß√£o equilibrada com concorrentes:**
        - A marca √© mencionada em mat√©rias onde recebe o mesmo peso e import√¢ncia dos concorrentes
        - Ambas as marcas s√£o tratadas de forma equilibrada na narrativa
        - A marca n√£o √© secund√°ria ou tangencial, mas co-protagonista da mat√©ria
        - Exemplo: "Goldman Sachs eleva recomenda√ß√£o de Bradesco a neutra; corta Santander Brasil para venda"
        - Exemplo: "O Santander saiu na frente no dia 30 de abril, com um resultado dentro do esperado. Agora, os holofotes se voltam para Bradesco e Ita√∫."

        **N√≠vel 3 - Cita√ß√£o:**
        Este n√≠vel abrange tr√™s situa√ß√µes distintas:
        
        a) **Compara√ß√£o com concorrentes (marca claramente secund√°ria):**
        - A marca √© mencionada em mat√©rias claramente focadas em outro concorrente
        - A marca tem papel evidentemente secund√°rio na narrativa
        - A mat√©ria √© sobre o concorrente, apenas citando a marca para compara√ß√£o
        - Exemplo: Mat√©ria sobre "Resultados do Ita√∫ superam expectativas" que apenas menciona Bradesco para comparar estrat√©gias
        
        b) **Refer√™ncia setorial:**
        - A marca ou seus porta-vozes s√£o citados como refer√™ncia no setor ou sobre tema espec√≠fico
        - Atrav√©s de declara√ß√µes ou dados fornecidos pela empresa
        - Exemplo: "Segundo o Bradesco, o n√∫mero de empr√©stimos em S√£o Paulo cresceu 20% no √∫ltimo ano"
        
        c) **Men√ß√£o tangencial:**
        - Men√ß√£o onde a presen√ßa da marca n√£o √© crucial para a mat√©ria
        - Exemplo: "Empresas inovadoras como iFood, Nubank, Bradesco, e outras..."

        ATEN√á√ÉO - REGRAS ESPECIAIS PARA MARCAS COMPOSTAS:
        
        - Se analisando "Bradesco": APENAS conte "Bradesco" quando aparecer ISOLADO. N√ÉO conte "Bradesco BBI", "Bradesco Asset", ou outras varia√ß√µes compostas.
        - Se analisando "BBI": conte "BBI" isolado E "Bradesco BBI".  
        - Se analisando "Bradesco Asset": conte APENAS "Bradesco Asset" completo.
        - Se analisando "√Ågora": conte "√Ågora" isolado (sem varia√ß√µes conhecidas).
        
        REGRA CR√çTICA PARA MARCAS COMPOSTAS: 
        - Se a marca "{marca}" aparecer APENAS como parte de marcas compostas (ex: "Bradesco" s√≥ em "Bradesco Asset"), responda "Nenhum N√≠vel Encontrado".
        - Se a marca "{marca}" aparecer ISOLADA no texto, classifique pelos n√≠veis normais.
        - Esta regra tem PRIORIDADE ABSOLUTA.
        - Se analisando "Ita√∫": APENAS conte "Ita√∫" quando aparecer ISOLADO. N√ÉO conte "Ita√∫ Unibanco" ou outras varia√ß√µes compostas.
        
        REGRA ESPECIAL PARA COMPARA√á√ïES EQUILIBRADAS:
        - Se a marca aparece em t√≠tulos ou conte√∫dos onde m√∫ltiplas marcas recebem recomenda√ß√µes/an√°lises similares, classifique como "N√≠vel 2" (Conte√∫do).
        - Sinais de compara√ß√£o equilibrada: "eleva X e corta Y", "X sobe enquanto Y desce", "recomenda√ß√µes para X e Y".
        - Se ambas as marcas est√£o no t√≠tulo com a√ß√µes equivalentes = N√≠vel 2, n√£o N√≠vel 3.
        
        EXEMPLO IMPORTANTE:
        - Texto: "Segundo o Bradesco Asset, o mercado cresceu"
        - An√°lise para "Bradesco": ‚Üí "Nenhum N√≠vel Encontrado" (apenas "Bradesco Asset", n√£o "Bradesco" isolado)
        - An√°lise para "Bradesco Asset": ‚Üí "N√≠vel 3" ou superior (men√ß√£o direta)
        
        EXEMPLO DE COMPARA√á√ÉO EQUILIBRADA:
        - Texto: "Goldman Sachs eleva recomenda√ß√£o de Bradesco a neutra; corta Santander Brasil para venda"
        - An√°lise para "Santander": ‚Üí "N√≠vel 2" (Conte√∫do) - ambas as marcas recebem recomenda√ß√µes no t√≠tulo, tratamento equilibrado
        
        {self._build_specific_requirements(content_check, marca)}
        APENAS responda "Nenhum N√≠vel Encontrado" se a marca "{marca}" N√ÉO aparecer ISOLADAMENTE no texto (considerando as regras especiais acima).

        Analise o texto abaixo e responda SOMENTE com: "N√≠vel 1", "N√≠vel 2", "N√≠vel 3" ou "Nenhum N√≠vel Encontrado".

        Texto da Not√≠cia:
        {texto_noticia}
        """

        try:
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system", 
                        "content": "Voc√™ √© um analista especializado em classificar o n√≠vel de protagonismo de marcas em not√≠cias. Use os crit√©rios fornecidos de forma rigorosa mas inclusiva - qualquer men√ß√£o da marca deve ser pelo menos N√≠vel 3 (Cita√ß√£o). Considere verifica√ß√µes espec√≠ficas quando informadas."
                    },
                    {"role": "user", "content": prompt_texto}
                ],
                "temperature": 0.1
            }
            
            response = requests.post(self.config.api_url, headers=self.headers, json=payload)
            response.raise_for_status()
            
            nivel_detectado = response.json()['choices'][0]['message']['content'].strip()
            nivel_detectado_limpo = nivel_detectado.replace(":", "").strip()
            
            # LOG ESPEC√çFICO para controle de chamadas DeepSeek
            self.logger.info(f"DeepSeek API ‚Üí ID: {noticia_id} | Marca: {marca} | Resultado: {nivel_detectado_limpo}")
            
            return nivel_detectado_limpo
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Erro na requisi√ß√£o para not√≠cia ID {noticia_id}, marca {marca}: {str(e)}")
            return 'Erro na API'
        except Exception as e:
            self.logger.error(f"Erro inesperado ao processar not√≠cia ID {noticia_id}, marca {marca}: {str(e)}")
            return 'Erro de Processamento'
    
    
    def _correct_missing_classifications_largo(self, df_resultados: pd.DataFrame, final_df: pd.DataFrame) -> pd.DataFrame:
        """
        Corrige classifica√ß√µes faltantes ou incorretas baseado na contagem de ocorr√™ncias
        ATUALIZADO: Funciona com formato largo e inclui verifica√ß√£o de porta-vozes
        CORRIGIDO: Usa verifica√ß√£o de marca isolada no t√≠tulo
        """
        self.logger.info("Iniciando corre√ß√£o p√≥s-processamento baseada na contagem de ocorr√™ncias...")
        
        correcoes_realizadas = 0
        
        # Cache de textos das not√≠cias para evitar buscas repetidas
        noticias_dict = {}
        for _, row in final_df.iterrows():
            noticia_id = row['Id']
            titulo = str(row.get('Titulo', '')).strip()
            conteudo = str(row.get('Conteudo', '')).strip()
            noticias_dict[noticia_id] = {
                'titulo': titulo, 
                'conteudo': conteudo
            }
        
        # Cache de porta-vozes por not√≠cia (detecta uma vez por not√≠cia)
        porta_vozes_por_noticia = {}
        
        # Processa cada linha do DataFrame resultado
        for index, row in df_resultados.iterrows():
            noticia_id = row['Id']
            
            if noticia_id in noticias_dict:
                titulo = noticias_dict[noticia_id]['titulo']
                conteudo = noticias_dict[noticia_id]['conteudo']
                
                # Detecta porta-vozes UMA VEZ por not√≠cia
                if noticia_id not in porta_vozes_por_noticia:
                    porta_vozes_por_noticia[noticia_id] = self._check_porta_voz_mentioned(titulo, conteudo)
                
                for marca in self.config.w_marcas:
                    nivel_col = f'Nivel de Protagonismo {marca}'
                    ocorrencias_col = f'Ocorrencias {marca}'
                    
                    nivel_atual = row.get(nivel_col)
                    contagem = row.get(ocorrencias_col, 0)
                    
                    # Se n√£o h√° classifica√ß√£o ou √© "Nenhum N√≠vel Encontrado"
                    if pd.isna(nivel_atual) or nivel_atual == 'Nenhum N√≠vel Encontrado':
                        
                        # ‚ïê‚ïê‚ïê OBTER MARCAS COMPOSTAS ‚ïê‚ïê‚ïê
                        marcas_compostas = self._get_marcas_compostas_para_marca_base(marca)
                        
                        # ‚ïê‚ïê‚ïê CONTAGEM DE OCORR√äNCIAS ‚ïê‚ïê‚ïê
                        contagem = self._count_marca_occurrences_fixed(marca, titulo, conteudo, marcas_compostas)
                        
                        # Se encontrou ocorr√™ncias, reclassifica baseado na quantidade
                        if contagem > 0:
                            # Determina o n√≠vel baseado na quantidade de ocorr√™ncias
                            if contagem >= 5:
                                nivel_corrigido = 'N√≠vel 1'  # Dedicada
                                nome_nivel = 'Dedicada'
                            elif contagem >= 3:  # 3-4 ocorr√™ncias
                                nivel_corrigido = 'N√≠vel 2'  # Conte√∫do
                                nome_nivel = 'Conte√∫do'
                            else:  # 1-2 ocorr√™ncias
                                nivel_corrigido = 'N√≠vel 3'  # Cita√ß√£o
                                nome_nivel = 'Cita√ß√£o'
                            
                            # ‚ïê‚ïê‚ïê CORRE√á√ÉO: Verificar se marca est√° ISOLADA no t√≠tulo ‚ïê‚ïê‚ïê
                            marca_isolada = self._verificar_marca_isolada_no_titulo(marca, titulo, marcas_compostas)
                            if marca_isolada:
                                nivel_corrigido = 'N√≠vel 1'
                                nome_nivel = 'Dedicada (marca isolada no t√≠tulo)'
                            
                            self.logger.info(f"Corrigindo classifica√ß√£o - Not√≠cia ID {noticia_id}, Marca {marca}: "
                                           f"'{nivel_atual}' ‚Üí '{nome_nivel}' ({contagem} ocorr√™ncias)")
                            
                            # Limitar ocorr√™ncias a no m√°ximo 10
                            contagem = min(contagem, 10)
                            
                            df_resultados.loc[index, nivel_col] = nivel_corrigido
                            df_resultados.loc[index, ocorrencias_col] = contagem
                            correcoes_realizadas += 1
                        else:
                            self.logger.debug(f"Mantendo classifica√ß√£o - Not√≠cia ID {noticia_id}, Marca {marca}: "
                                            f"marca n√£o encontrada no texto")
                        
                        # ‚ïê‚ïê‚ïê APLICAR PORTA-VOZES (apenas para marcas COM classifica√ß√£o v√°lida) ‚ïê‚ïê‚ïê
                        if marca in ['Bradesco', '√Ågora', 'Bradesco Asset', 'BBI']:
                            # CORRE√á√ÉO: Verificar se marca tem classifica√ß√£o antes de aplicar porta-voz
                            nivel_col = f'Nivel de Protagonismo {marca}'
                            nivel_atual = df_resultados.loc[index, nivel_col] if nivel_col in df_resultados.columns else None
                            
                            # S√≥ aplicar porta-voz se marca tem classifica√ß√£o v√°lida
                            if pd.notna(nivel_atual) and nivel_atual != 'Nenhum N√≠vel Encontrado':
                                porta_vozes_noticia = porta_vozes_por_noticia.get(noticia_id, [])
                                
                                if porta_vozes_noticia:
                                    # Preenche coluna de porta-voz
                                    portavoz_col = f'Porta-Voz {marca}'
                                    if portavoz_col in df_resultados.columns:
                                        porta_vozes_str = ', '.join(porta_vozes_noticia)
                                        df_resultados.loc[index, portavoz_col] = porta_vozes_str
                                        self.logger.info(f"Porta-vozes aplicados para {marca} (classifica√ß√£o: {nivel_atual}): {porta_vozes_str}")
                                    
                                    # Upgrade para Conte√∫do s√≥ se for Cita√ß√£o por contagem 
                                    if 'contagem' in locals() and contagem >= 1 and contagem <= 2:
                                        df_resultados.loc[index, nivel_col] = 'N√≠vel 2'  # Upgrade para Conte√∫do
                                        self.logger.info(f"Upgrade para Conte√∫do por porta-voz: {marca}")
                            else:
                                self.logger.debug(f"Porta-voz N√ÉO aplicado para {marca}: sem classifica√ß√£o v√°lida (n√≠vel atual: {nivel_atual})")
            else:
                self.logger.warning(f"Texto n√£o encontrado para not√≠cia ID {noticia_id}")
        
        self.logger.info(f"Corre√ß√£o p√≥s-processamento conclu√≠da: {correcoes_realizadas} classifica√ß√µes corrigidas")
        
        return df_resultados
    
    def _apply_nivel_substitutions_largo(self, df_resultados: pd.DataFrame) -> pd.DataFrame:
        """
        Aplica as substitui√ß√µes dos n√≠veis conforme especificado
        ATUALIZADO: Funciona com formato largo
        """
        self.logger.info("Aplicando substitui√ß√µes dos nomes dos n√≠veis...")
        
        # Mapeamento baseado no arquivo Bradesco
        substituicoes = {
            "N√≠vel 1": "Dedicada",
            "N√≠vel 2": "Conte√∫do", 
            "N√≠vel 3": "Cita√ß√£o"
        }
        
        # Aplica substitui√ß√µes em todas as colunas de n√≠vel
        for marca in self.config.w_marcas:
            nivel_col = f'Nivel de Protagonismo {marca}'
            if nivel_col in df_resultados.columns:
                df_resultados[nivel_col] = df_resultados[nivel_col].apply(
                    lambda x: substituicoes.get(x, x) if pd.notna(x) else x
                )
        
        self.logger.info("Substitui√ß√µes conclu√≠das")
        return df_resultados
    
    def _save_results_largo(self, df_resultados: pd.DataFrame):
        """
        Salva os resultados da an√°lise de protagonismo no formato largo
        ATUALIZADO: Inclui colunas de ocorr√™ncias
        Remove colunas de porta-vozes do Ita√∫ e Santander antes de salvar
        """
        try:
            # NOVO: Remove colunas de Porta-Voz do Ita√∫ e Santander (se existirem)
            colunas_para_remover = []
            for marca in ['Ita√∫', 'Santander']:
                col_portavoz = f'Porta-Voz {marca}'
                if col_portavoz in df_resultados.columns:
                    colunas_para_remover.append(col_portavoz)
            
            if colunas_para_remover:
                df_resultados = df_resultados.drop(columns=colunas_para_remover)
                self.logger.info(f"Colunas de porta-vozes removidas: {colunas_para_remover}")
            
            # Verifica√ß√£o antes de salvar
            self.logger.info("=== PREPARANDO PARA SALVAR ===")
            self.logger.info(f"DataFrame a ser salvo: {len(df_resultados)} registros")
            self.logger.info(f"Colunas a serem salvas: {list(df_resultados.columns)}")
            
            # Verificar se as colunas obrigat√≥rias est√£o presentes
            colunas_obrigatorias = ['Id', 'UrlVisualizacao', 'UrlOriginal', 'Titulo']
            for marca in self.config.w_marcas:
                colunas_obrigatorias.extend([
                    f'Nivel de Protagonismo {marca}',
                    f'Ocorrencias {marca}'
                ])
                
                # ATUALIZADO: Porta-vozes s√£o obrigat√≥rias para Bradesco, √Ågora, Bradesco Asset e BBI
                if marca in ['Bradesco', '√Ågora', 'Bradesco Asset', 'BBI']:
                    colunas_obrigatorias.append(f'Porta-Voz {marca}')
            
            colunas_faltantes = [col for col in colunas_obrigatorias if col not in df_resultados.columns]
            if colunas_faltantes:
                self.logger.error(f"ERRO: Tentando salvar sem colunas obrigat√≥rias: {colunas_faltantes}")
                raise ValueError(f"Colunas obrigat√≥rias faltantes: {colunas_faltantes}")
            
            # Gera timestamp para o nome do arquivo
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Define o caminho com timestamp
            base_path = str(self.config.arq_protagonismo_result).replace('.xlsx', f'_{timestamp}.xlsx')
            
            # Salva arquivo com timestamp
            df_resultados.to_excel(base_path, index=False)
            self.logger.info(f"Resultados de protagonismo salvos: {base_path}")
            
            # Tamb√©m salva arquivo padr√£o para compatibilidade com outras etapas
            df_resultados.to_excel(self.config.arq_protagonismo_result, index=False)
            self.logger.info(f"Arquivo padr√£o salvo: {self.config.arq_protagonismo_result}")
            
            # Log final da estrutura salva
            self.logger.info("=== ARQUIVO SALVO COM SUCESSO ===")
            self.logger.info(f"Estrutura final: {list(df_resultados.columns)}")
            
        except Exception as e:
            self.logger.error(f"Erro ao salvar resultados: {str(e)}")
            raise
    
    # === M√âTODOS ANTIGOS MANTIDOS PARA COMPATIBILIDADE ===
    def _process_noticias(self, final_df: pd.DataFrame, df_protagonismo: pd.DataFrame) -> List[Dict]:
        """
        M√âTODO ORIGINAL MANTIDO PARA COMPATIBILIDADE
        Redireciona para o novo m√©todo de formato largo
        """
        self.logger.warning("M√©todo _process_noticias antigo foi chamado. Redirecionando para formato largo.")
        df_largo = self._process_noticias_formato_largo(final_df, df_protagonismo)
        
        # Converte de volta para o formato lista para compatibilidade
        resultados = []
        for _, row in df_largo.iterrows():
            for marca in self.config.w_marcas:
                nivel_col = f'Nivel de Protagonismo {marca}'
                nivel = row[nivel_col]
                if pd.notna(nivel):
                    resultados.append({
                        'Id': row['Id'],
                        'Marca': marca,
                        'Nivel': nivel
                    })
        
        return resultados
    
    def _apply_nivel_substitutions(self, df_resultados: pd.DataFrame) -> pd.DataFrame:
        """
        M√âTODO ORIGINAL MANTIDO PARA COMPATIBILIDADE
        """
        return self._apply_nivel_substitutions_largo(df_resultados)
    
    def _correct_missing_classifications(self, df_resultados: pd.DataFrame, final_df: pd.DataFrame) -> pd.DataFrame:
        """
        M√âTODO ORIGINAL MANTIDO PARA COMPATIBILIDADE
        """
        return self._correct_missing_classifications_largo(df_resultados, final_df)
    
    def _save_results(self, df_resultados: pd.DataFrame):
        """
        M√âTODO ORIGINAL MANTIDO PARA COMPATIBILIDADE
        """
        return self._save_results_largo(df_resultados)